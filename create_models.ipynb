{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46430\n",
      "45504\n",
      "36446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "fake_data = pd.read_csv('Panorama/metatable.csv', sep='\\t')\n",
    "\n",
    "data = []\n",
    "for i in range(fake_data.shape[0]):\n",
    "    file = open('Panorama/texts/'+str(i)+'.txt')\n",
    "    data.append(' '.join(file.readlines()))\n",
    "fake_data = pd.concat([fake_data, pd.DataFrame(data, columns=['text'])], axis=1)\n",
    "fake_data['text'] = fake_data['text'].str.lower().str.replace('\\s', ' ').\\\n",
    "                                      str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "fake_data['title'] = fake_data['title'].str.lower().str.replace('\\s', ' ').\\\n",
    "                                      str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "fake_data = fake_data[['text', 'title', 'date', 'link']]\n",
    "\n",
    "def get_data(news):\n",
    "    data = []\n",
    "    meta_data = pd.read_csv(news + '/newmetadata.csv', sep='\\t').drop_duplicates()\n",
    "    for name in os.listdir(news + '/texts'):\n",
    "        file = open(news + '/texts/'+name)\n",
    "        data.append(' '.join(file.readlines()))\n",
    "    \n",
    "    data = pd.DataFrame({'text': data, 'textid': os.listdir(news + '/texts')})\n",
    "    meta_data = pd.concat([meta_data.sort_values(['textid']).reset_index(drop=True),\n",
    "                               data.sort_values(['textid']).reset_index(drop=True)['text']], axis=1)\n",
    "    meta_data['text'] = meta_data['text'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "    meta_data['textname'] = meta_data['textname'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "    return meta_data[['text', 'textname', 'date', 'source']].sort_values(['date']).reset_index(drop=True).\\\n",
    "                                                             rename({'textname':'title'}, axis=1)\n",
    "\n",
    "interfax_data = get_data('interfax')\n",
    "print(interfax_data.shape[0])\n",
    "\n",
    "kp_data = get_data('KP')\n",
    "print(kp_data.shape[0])\n",
    "\n",
    "lenta_data = get_data('Lenta')\n",
    "print(lenta_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20761\n"
     ]
    }
   ],
   "source": [
    "eng_data = pd.read_csv('fake-news/train.csv').drop(columns=['id'])\n",
    "eng_data['text'] = eng_data['text'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "eng_data['title'] = eng_data['title'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "eng_data.drop(index=eng_data.index[eng_data.text.isnull()], inplace=True)\n",
    "print(eng_data.shape[0])\n",
    "\n",
    "emd1_texts = pd.read_csv('all-the-news/articles1.csv')['content'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "emd2_texts = pd.read_csv('all-the-news/articles2.csv')['content'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "emd3_texts = pd.read_csv('all-the-news/articles3.csv')['content'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emb = 'eng_rus'\n",
    "#dict_emb = 'rus'\n",
    "\n",
    "\n",
    "texts = [lenta_data.iloc[i].text.split() for i in range(len(lenta_data))]\n",
    "texts += [kp_data.iloc[i].text.split() for i in range(len(kp_data))]\n",
    "texts += [interfax_data.iloc[i].text.split() for i in range(len(interfax_data))]\n",
    "\n",
    "#texts += [eng_data.iloc[i].text.split() for i in range(len(eng_data))]\n",
    "\n",
    "if dict_emb == 'eng_rus':\n",
    "    texts += [emd1_texts.iloc[i].split() for i in range(len(emd1_texts))]\n",
    "    texts += [emd2_texts.iloc[i].split() for i in range(len(emd2_texts))]\n",
    "    texts += [emd3_texts.iloc[i].split() for i in range(len(emd3_texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 55s, sys: 8.76 s, total: 22min 4s\n",
      "Wall time: 6min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "\n",
    "n = 64\n",
    "model = Word2Vec(texts, size=n, window=10, min_count=5, workers=12)\n",
    "model.save(\"model/word2vec_\" + dict_emb + \".bin\")\n",
    "model = Word2Vec.load(\"model/word2vec_\" + dict_emb + \".bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "n_tm = 64\n",
    "model = LdaModel(corpus, num_topics = n_tm)\n",
    "model.save(\"model/lda_\" + dict_emb + \".bin\")\n",
    "model = LdaModel.load(\"model/lda_\" + dict_emb + \".bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "docs = []\n",
    "for i in range(len(texts)):\n",
    "    docs.append(TaggedDocument(texts[i], [str(i)]))\n",
    "    \n",
    "n_d2v = 64\n",
    "model = Doc2Vec(vector_size=n_d2v, window=8, min_count=5, workers=12, alpha=0.025, min_alpha=0.01, dm=0, epochs=10)\n",
    "model.build_vocab(docs)\n",
    "model.train(docs, total_examples=len(docs), epochs=20)\n",
    "model.save(\"model/doc2vec_\" + dict_emb + \".bin\")\n",
    "model = Doc2Vec.load(\"model/doc2vec_\" + dict_emb + \".bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
