{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "fake_data = pd.read_csv('Panorama/metatable.csv', sep='\\t')\n",
    "\n",
    "data = []\n",
    "for i in range(fake_data.shape[0]):\n",
    "    file = open('Panorama/texts/'+str(i)+'.txt')\n",
    "    data.append(' '.join(file.readlines()))\n",
    "fake_data = pd.concat([fake_data, pd.DataFrame(data, columns=['text'])], axis=1)\n",
    "fake_data['text'] = fake_data['text'].str.lower().str.replace('\\s', ' ').\\\n",
    "                                      str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "fake_data['title'] = fake_data['title'].str.lower().str.replace('\\s', ' ').\\\n",
    "                                      str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "fake_data = fake_data[['text', 'title', 'date', 'link']]\n",
    "\n",
    "def get_data(news):\n",
    "    data = []\n",
    "    meta_data = pd.read_csv(news + '/newmetadata.csv', sep='\\t').drop_duplicates()\n",
    "    for name in os.listdir(news + '/texts'):\n",
    "        file = open(news + '/texts/'+name)\n",
    "        data.append(' '.join(file.readlines()))\n",
    "    \n",
    "    data = pd.DataFrame({'text': data, 'textid': os.listdir(news + '/texts')})\n",
    "    meta_data = pd.concat([meta_data.sort_values(['textid']).reset_index(drop=True),\n",
    "                               data.sort_values(['textid']).reset_index(drop=True)['text']], axis=1)\n",
    "    meta_data['text'] = meta_data['text'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "    meta_data['textname'] = meta_data['textname'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "    return meta_data[['text', 'textname', 'date', 'source']].sort_values(['date']).reset_index(drop=True).\\\n",
    "                                                             rename({'textname':'title'}, axis=1)\n",
    "\n",
    "interfax_data = get_data('interfax')\n",
    "kp_data = get_data('KP')\n",
    "lenta_data = get_data('Lenta')\n",
    "\n",
    "eng_data = pd.read_csv('fake-news/train.csv').drop(columns=['id'])\n",
    "eng_data['text'] = eng_data['text'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "eng_data['title'] = eng_data['title'].str.lower().str.replace('\\s', ' ').str.replace(r'[^a-zа-я0-9 ]', '')\n",
    "eng_data.drop(index=eng_data.index[eng_data.text.isnull()], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fake = np.ones(fake_data.shape[0])\n",
    "np.save('ru-eng/fake/y.npy', y_fake)\n",
    "\n",
    "y_kp = np.zeros(kp_data.shape[0])\n",
    "y_lenta = np.zeros(lenta_data.shape[0])\n",
    "y_interfax = np.zeros(interfax_data.shape[0])\n",
    "y_true = np.concatenate([y_interfax, y_lenta, y_kp])\n",
    "np.save('ru-eng/true/y.npy', y_true)\n",
    "\n",
    "y_eng = eng_data.label\n",
    "np.save('ru-eng/eng/y.npy', y_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "model = Doc2Vec.load(\"model/doc2vec_eng_rus.bin\")\n",
    "n_d2v = 64\n",
    "\n",
    "\n",
    "def create_d2v(data, model, name):\n",
    "    texts = [str(data.iloc[i][name]).split() for i in range(len(data))]\n",
    "    X_d2v = np.zeros((len(data), n_d2v))\n",
    "    for i in range(len(data)):\n",
    "        X_d2v[i] = model.infer_vector(texts[i])\n",
    "    return X_d2v\n",
    "\n",
    "def save_emb(func, name):\n",
    "    X_fake = func(fake_data, model, 'text')\n",
    "    np.save('ru-eng/fake/text_' + name + '.npy', X_fake)\n",
    "\n",
    "    X_kp = func(kp_data, model, 'text')\n",
    "    X_lenta = func(lenta_data, model, 'text')\n",
    "    X_interfax = func(interfax_data, model, 'text')\n",
    "    X_true = np.vstack([X_interfax, X_lenta, X_kp])\n",
    "    np.save('ru-eng/true/text_' + name + '.npy', X_true)\n",
    "\n",
    "    X_eng = func(eng_data, model, 'text')\n",
    "    np.save('ru-eng/eng/text_' + name + '.npy', X_eng)\n",
    "\n",
    "\n",
    "    X_fake = func(fake_data, model, 'title')\n",
    "    np.save('ru-eng/fake/title_' + name + '.npy', X_fake)\n",
    "\n",
    "    X_kp = func(kp_data, model, 'title')\n",
    "    X_lenta = func(lenta_data, model, 'title')\n",
    "    X_interfax = func(interfax_data, model, 'title')\n",
    "    X_true = np.vstack([X_interfax, X_lenta, X_kp])\n",
    "    np.save('ru-eng/true/title_' + name + '.npy', X_true)\n",
    "\n",
    "    X_eng = func(eng_data, model, 'title')\n",
    "    np.save('ru-eng/eng/title_' + name + '.npy', X_eng)\n",
    "\n",
    "save_emb(create_d2v, 'd2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "model = Word2Vec.load(\"model/word2vec_eng_rus.bin\")\n",
    "n_w2v = 64\n",
    "\n",
    "def create_w2v(data, model, name):\n",
    "    X = np.zeros((len(data), n_w2v))\n",
    "    texts = [str(data.iloc[i][name]).split() for i in range(len(data))]\n",
    "    for i in range(len(data)):\n",
    "        k = 0\n",
    "        for j in range(len(texts[i])):\n",
    "            if texts[i][j] in model.wv.vocab:\n",
    "                X[i] += model[texts[i][j]]\n",
    "                k += 1\n",
    "        X[i] /= k\n",
    "    return X\n",
    "        \n",
    "save_emb(create_w2v, 'w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "\n",
    "model = LdaModel.load(\"model/lda_eng_rus.bin\")\n",
    "n_tm = 64\n",
    "\n",
    "def create_lda(data, model, name):\n",
    "    texts = [str(data.iloc[i][name]).split() for i in range(len(data))]\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    X_tm = np.zeros((len(data), n_tm))\n",
    "    for i in range(len(data)):\n",
    "        for elem in model[corpus[i]]:\n",
    "            X_tm[i][elem[0]] = elem[1]\n",
    "            \n",
    "    return X_tm\n",
    "\n",
    "save_emb(create_lda, 'lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
